{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard RMM experiments\n",
    "\n",
    "This notebook accumulates experiments for all benchmark datasets that can be handled with standard reservoir memory machines, in particular the latch, copy, repeat copy, signal copy, and image copy task. FSM learning and associative recall require some special concepts and are handled in separate notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in this first cell we set some experimental meta-parameters that are used across all\n",
    "# datasets\n",
    "\n",
    "# the number of training time series\n",
    "N = 90\n",
    "# the number of test time series\n",
    "N_test = 10\n",
    "# the number of repeats for the experiments\n",
    "R = 10\n",
    "# the names of the tasks to be performed\n",
    "tasks = ['latch', 'copy', 'repeat_copy', 'signal_copy', 'image_copy']\n",
    "# the number of neurons for each task\n",
    "num_neurons = [64, 256, 256, 64, 512]\n",
    "# the number of input dimensions for each task\n",
    "ns = [1, 9, 9, 2, 28]\n",
    "# the horizons for each task\n",
    "Ts = [256, 24, 16, 312, 32]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the number of hyperparameter combinations to be tested\n",
    "hyper_R = 10\n",
    "# the number of repeats for each hyperparameter combination\n",
    "hyper_num_repeats = 1\n",
    "# set the hyper-parameter ranges for all models\n",
    "models = ['RMM_CRJ']\n",
    "hyperparam_ranges = {\n",
    "    'ESN' : {\n",
    "        'radius' : [0.5, 0.7, 0.9],\n",
    "        'sparsity' : [0.1, 0.2, 0.5],\n",
    "        'regul' : [1E-7, 1E-5, 1E-3]\n",
    "    },\n",
    "    'CRJ' : {\n",
    "        'v' : [0.1, 0.3, 0.5],\n",
    "        'w_c' : [0.1, 0.7, 0.9],\n",
    "        'w_j' : [0.1, 0.2, 0.4],\n",
    "        'l' : [4, 8, 16],\n",
    "        'regul' : [1E-7, 1E-5, 1E-3]\n",
    "    },\n",
    "    'LMU' : {\n",
    "        'regul' : [1E-7, 1E-5, 1E-3],\n",
    "        #'T' : [16, 32, 128, 384]\n",
    "    },\n",
    "    'RMM_ESN' : {\n",
    "        'radius' : [0.5, 0.7, 0.9],\n",
    "        'sparsity' : [0.1, 0.2, 0.5],\n",
    "        'regul' : [1E-7, 1E-5, 1E-3],\n",
    "        'C' : [1., 100., 10000.],\n",
    "        'svm_kernel' : ['linear', 'rbf'],\n",
    "        'lr': [1E-6, 5e-6, 1E-5, 5e-5, 1E-4, 5e-4, 1E-3],\n",
    "        'u': [0.1, 0.5, 0.8, 1.0]\n",
    "    },\n",
    "    'RMM_CRJ' : {\n",
    "        'v' : [0.1, 0.3, 0.5],\n",
    "        'w_c' : [0.1, 0.7, 0.9],\n",
    "        'w_j' : [0.1, 0.2, 0.4],\n",
    "        'l' : [4, 8, 16],\n",
    "        'regul' : [1E-7, 1E-5, 1E-3],\n",
    "        'C' : [1., 100., 10000.],\n",
    "        'svm_kernel' : ['linear', 'rbf'],\n",
    "        'lr': [1E-6, 5e-6, 1E-5, 5e-5, 1E-4, 5e-4, 1E-3],\n",
    "        'u': [0.1, 0.5, 0.8, 1.0]\n",
    "    },\n",
    "    'RMM_LMU' : {\n",
    "        'regul' : [1E-7, 1E-5, 1E-3],\n",
    "        'C' : [1., 100., 10000.],\n",
    "        #'T' : [16, 32, 128, 384],\n",
    "        'svm_kernel' : ['linear', 'rbf'],\n",
    "        'lr': [1E-6, 5e-6, 1E-5, 5e-5, 1E-4, 5e-4, 1E-3],\n",
    "        'u': [0.1, 0.5, 0.8, 1.0]\n",
    "    }\n",
    "}\n",
    "\n",
    "import numpy as np\n",
    "import rmm2.esn as esn\n",
    "import rmm2.crj as crj\n",
    "import rmm2.lmu as lmu\n",
    "import rmm2.rmm as rmm\n",
    "\n",
    "# set up a function to initialize an instance for each model\n",
    "def setup_model(model, m, n, hyperparams):\n",
    "    # first, set up the correct reservoir and nonlinearity\n",
    "    if model.endswith('ESN'):\n",
    "        U, W = esn.initialize_reservoir(m, n, radius = hyperparams['radius'],\n",
    "                                        sparsity = hyperparams['sparsity'])\n",
    "        nonlin = np.tanh\n",
    "    elif model.endswith('CRJ'):\n",
    "        U = crj.setup_input_weight_matrix(n, m, v = hyperparams['v'])\n",
    "        W = crj.setup_reservoir_matrix(m, w_c = hyperparams['w_c'],\n",
    "                                       w_j = hyperparams['w_j'], l = hyperparams['l'])\n",
    "        nonlin = np.tanh\n",
    "    elif model.endswith('LMU'):\n",
    "        degree = int(m/n)-1\n",
    "        U, W = lmu.initialize_reservoir(n, degree, hyperparams['T'])\n",
    "        nonlin = lambda x : x\n",
    "    else:\n",
    "        raise ValueError('Unknown model: %s' % model)\n",
    "    # then, set up the model\n",
    "    if not model.startswith('RMM_'):\n",
    "        net = esn.ESN(U, W, regul = hyperparams['regul'], input_normalization = False,\n",
    "                      nonlin = nonlin)\n",
    "    else:\n",
    "        net = rmm.RMM(U, W, lr = hyperparams['lr'], u = hyperparams['u'], regul = hyperparams['regul'], input_normalization = False,\n",
    "                      nonlin = nonlin, C = hyperparams['C'],\n",
    "                      svm_kernel = hyperparams['svm_kernel'])\n",
    "    return net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment\n",
    "\n",
    "After all the hyperparameter setup above we can now iterate over all tasks and\n",
    "first perform hyperparameter optimization, followed by the actual experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Task 2 of 5: copy -----\n",
      "performing hyperparameter optimization (this may take a while)\n",
      "--- repeat 1 of 1 ---\n",
      "-- model: RMM_CRJ --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alok2\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State prediction recall: 0.809913; precision: 0.809913\n",
      "error: 0.487018\n",
      "State prediction recall: 0.337344; precision: 0.337344\n",
      "error: 0.468135\n",
      "State prediction recall: 0.361405; precision: 0.361405\n",
      "error: 0.514518\n",
      "State prediction recall: 0.45717; precision: 0.45717\n",
      "error: 0.631656\n",
      "State prediction recall: 0.263234; precision: 0.263234\n",
      "error: 0.50774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alok2\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State prediction recall: 0.812801; precision: 0.812801\n",
      "error: 0.491269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alok2\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State prediction recall: 0.921078; precision: 0.921078\n",
      "error: 0.625274\n",
      "State prediction recall: 0.258903; precision: 0.258903\n",
      "error: 0.498921\n",
      "State prediction recall: 0.498556; precision: 0.498556\n",
      "error: 0.585841\n",
      "State prediction recall: 0.66795; precision: 0.66795\n",
      "error: 0.488629\n",
      "\n",
      "Selected the following hyper-parameters for RMM_CRJ\n",
      "v: 0.3\n",
      "w_c: 0.1\n",
      "w_j: 0.4\n",
      "l: 16\n",
      "regul: 1e-05\n",
      "C: 100.0\n",
      "svm_kernel: linear\n",
      "lr: 1e-06\n",
      "u: 0.5\n",
      "errors: [0.4681354639004606]\n",
      "--- repeat 1 of 10 ---\n",
      "State prediction recall: 0.324012; precision: 0.324012\n",
      "--- repeat 2 of 10 ---\n",
      "State prediction recall: 0.341584; precision: 0.341584\n",
      "--- repeat 3 of 10 ---\n",
      "State prediction recall: 0.345133; precision: 0.345133\n",
      "--- repeat 4 of 10 ---\n",
      "State prediction recall: 0.34104; precision: 0.34104\n",
      "--- repeat 5 of 10 ---\n",
      "State prediction recall: 0.345581; precision: 0.345581\n",
      "--- repeat 6 of 10 ---\n",
      "State prediction recall: 0.325215; precision: 0.325215\n",
      "--- repeat 7 of 10 ---\n",
      "State prediction recall: 0.331268; precision: 0.331268\n",
      "--- repeat 8 of 10 ---\n",
      "State prediction recall: 0.339114; precision: 0.339114\n",
      "--- repeat 9 of 10 ---\n",
      "State prediction recall: 0.339614; precision: 0.339614\n",
      "--- repeat 10 of 10 ---\n",
      "State prediction recall: 0.345146; precision: 0.345146\n",
      "RMM_CRJ: 0.48089 +- 0.0121181 (took 4.70145 seconds)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from dataset_generators import generate_data\n",
    "from dataset_generators import _permutation_sampling\n",
    "\n",
    "# iterate over all tasks\n",
    "for task_idx in range(1, 2):\n",
    "    task = tasks[task_idx]\n",
    "    print('------ Task %d of %d: %s -----' % (task_idx+1, len(tasks), task))\n",
    "    m = num_neurons[task_idx]\n",
    "    n = ns[task_idx]\n",
    "    # try to load the selected hyperparameters from file\n",
    "    hyperparam_path = '%s_hyperparams.json' % task\n",
    "    if os.path.isfile(hyperparam_path):\n",
    "        print('loading hyperparameters from %s' % hyperparam_path)\n",
    "        with open(hyperparam_path, 'r') as hyperparam_file:\n",
    "            hyperparams = json.load(hyperparam_file)\n",
    "    else:\n",
    "        # perform a hyperoptimization where we test R random hyperparameter\n",
    "        # settings for each model and perform num_repeats repeats to obtain\n",
    "        # statistics. The hyperparameters with the best mean performance across\n",
    "        # repeats will be selected\n",
    "        print('performing hyperparameter optimization (this may take a while)')\n",
    "        # generate random parameter combination for all models\n",
    "        hyperparams = {}\n",
    "        for model in models:\n",
    "            # initialize a hyperparameter dictionary for each combination\n",
    "            hyperparams[model] = []\n",
    "            for r in range(hyper_R):\n",
    "                hyperparams[model].append({})\n",
    "            # then iterate over each key and sample the parameter values\n",
    "            for key in hyperparam_ranges[model]:\n",
    "                param_range = hyperparam_ranges[model][key]\n",
    "                param_value_indices = _permutation_sampling(hyper_R, 0, len(param_range)-1)\n",
    "                for r in range(hyper_R):\n",
    "                    value = param_range[param_value_indices[r]]\n",
    "                    hyperparams[model][r][key] = value\n",
    "            for r in range(hyper_R):\n",
    "                # set up an extra key for the errors\n",
    "                hyperparams[model][r]['errors'] = []\n",
    "                # for the signal_copy dataset, use the 'pseudo' SVM, because everything\n",
    "                # else takes too long to train\n",
    "                if task == 'signal_copy' and model.startswith('RMM'):\n",
    "                    hyperparams[model][r]['svm_kernel'] = 'pseudo'\n",
    "                # set time horizon for LMU models\n",
    "                if model.endswith('LMU'):\n",
    "                    hyperparams[model][r]['T'] = Ts[task_idx]\n",
    "\n",
    "        for repeat in range(hyper_num_repeats):\n",
    "            print('--- repeat %d of %d ---' % (repeat+1, hyper_num_repeats))\n",
    "            # sample training and test data\n",
    "            Xs, Qs, Ys = generate_data(N, task)\n",
    "            Xs_test, Qs_test, Ys_test = generate_data(N_test, task)\n",
    "            # now iterate over all models\n",
    "            for model in models:\n",
    "                print('-- model: %s --' % model)\n",
    "                # and iterate over all parameter combinations for this model\n",
    "                for params_r in hyperparams[model]:\n",
    "                    # set up a model instance\n",
    "                    net = setup_model(model, m, n, params_r)\n",
    "                    # fit the model to the data\n",
    "                    if model.startswith('RMM_'):\n",
    "                        net.fit(Xs, Qs, Ys)\n",
    "                    else:\n",
    "                        net.fit(Xs, Ys)\n",
    "                    # measure the RMSE on the test data\n",
    "                    mse = 0.\n",
    "                    for i in range(N_test):\n",
    "                        Ypred = net.predict(Xs_test[i])\n",
    "                        mse   += np.mean((Ypred - Ys_test[i]) ** 2)\n",
    "                    rmse = np.sqrt(mse / N_test)\n",
    "                    params_r['errors'].append(rmse)\n",
    "                    print('error: %g' % rmse)\n",
    "        # write the results to a JSON file\n",
    "        with open(hyperparam_path, 'w') as hyperparam_file:\n",
    "            json.dump(hyperparams, hyperparam_file)\n",
    "\n",
    "    # select best hyperparameters for each model\n",
    "    hyperparams_opt = {}\n",
    "    for model in models:\n",
    "        min_err = np.inf\n",
    "        for params_r in hyperparams[model]:\n",
    "            if np.mean(params_r['errors']) < min_err:\n",
    "                min_err = np.mean(params_r['errors'])\n",
    "                hyperparams_opt[model] = params_r\n",
    "        print('\\nSelected the following hyper-parameters for %s' % model)\n",
    "        for key in hyperparams_opt[model]:\n",
    "            print('%s: %s' % (key, str(hyperparams_opt[model][key])))\n",
    "    # hyperparameter optimization complete\n",
    "    \n",
    "    # ACTUAL EXPERIMENT\n",
    "\n",
    "    # initialize error and runtime arrays\n",
    "    errors   = np.zeros((len(models), R))\n",
    "    runtimes = np.zeros((len(models), R))\n",
    "    # iterate over all experimental repeats\n",
    "    for r in range(R):\n",
    "        print('--- repeat %d of %d ---' % (r+1, R))\n",
    "        # sample training and test data\n",
    "        Xs, Qs, Ys = generate_data(N, task)\n",
    "        Xs_test, Qs_test, Ys_test = generate_data(N_test, task)\n",
    "        # now iterate over all models\n",
    "        for model_idx in range(len(models)):\n",
    "            model = models[model_idx]\n",
    "            # print('-- model: %s --' % model)\n",
    "            # set up the model with the best selected hyperparameters\n",
    "            start_time = time.time()\n",
    "            net = setup_model(model, m, n, hyperparams_opt[model])\n",
    "            # fit the model to the data\n",
    "            if model.startswith('RMM_'):\n",
    "                net.fit(Xs, Qs, Ys)\n",
    "            else:\n",
    "                net.fit(Xs, Ys)\n",
    "            # measure the RMSE on the test data\n",
    "            mse = 0.\n",
    "            for i in range(N_test):\n",
    "                Ypred = net.predict(Xs_test[i])\n",
    "                mse   += np.mean((Ypred - Ys_test[i]) ** 2)\n",
    "            rmse = np.sqrt(mse / N_test)\n",
    "            runtimes[model_idx, r] = time.time() - start_time\n",
    "            errors[model_idx, r] = rmse\n",
    "    # print results\n",
    "    for model_idx in range(len(models)):\n",
    "        print('%s: %g +- %g (took %g seconds)' % (models[model_idx], np.mean(errors[model_idx, :]), np.std(errors[model_idx, :]), np.mean(runtimes[model_idx, :])))\n",
    "    # write results to file\n",
    "    np.savetxt('%s_errors.csv' % task, errors.T, delimiter='\\t', header='\\t'.join(models), comments='')\n",
    "    np.savetxt('%s_runtimes.csv' % task, runtimes.T, delimiter='\\t', header='\\t'.join(models), comments='')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e1365735ce637560aa124fd0413d7f43902b449fdc75b168617a49a18bef1f7d"
  },
  "kernelspec": {
   "display_name": "Python 3.7.8 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
